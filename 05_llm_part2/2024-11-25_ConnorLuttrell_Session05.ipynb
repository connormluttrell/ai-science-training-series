{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a575241e-2e21-4113-bb57-c06b406dd23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/applications/miniconda3/conda_pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# load model and tokenizer\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "falcon_pipeline = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    device=0  # use GPU if available, set to -1 for CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae4ed3-310e-47b2-860b-c7b0677c7291",
   "metadata": {},
   "source": [
    "# Zero-shot Example\n",
    "* Model has the ability to handle new tasks without prior examples.\n",
    "* Evaluates model's interpretation level, generates answer based only on task details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14123748-4f7d-474e-864e-81d6d4c6aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add all the odd numbers in the list: 4, 8, 9, 15, 12, 2, 1. What is the total?\n",
      "The sum of all odd numbers in the list is 20 (4 + 8 + 9 + 15 + 12 + 2 + 1).\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt = \"Add all the odd numbers in the list: 4, 8, 9, 15, 12, 2, 1. What is the total?\"\n",
    "\n",
    "response_zero_shot = falcon_pipeline(\n",
    "    zero_shot_prompt,\n",
    "    max_new_tokens=50,  # define the generated output's length\n",
    "    temperature=0.5,\n",
    "    truncation=True,\n",
    "    do_sample=True,  # enable sampling\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_zero_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84722b-2ce8-43b8-ae14-5315f51a2d22",
   "metadata": {},
   "source": [
    "# Few-shot Example\n",
    "* Shows the model's generalization level when it's provided examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d10d3c5-4eaa-4d60-a696-671f99da98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are examples of how to compute the sum of odd numbers:\n",
      "Example 1: The odd numbers in [3, 4, 7, 8] are [3, 7]. The sum is 10.\n",
      "Example 2: The odd numbers in [2, 5, 11, 14] are [5, 11]. The sum is 16.\n",
      "Question: What is the sum of the odd numbers in [4, 8, 9, 15, 12, 2, 1]?\n",
      "Answer: The sum of the odd numbers in [4, 8, 9, 15, 12, 2, 1] is 17.\n",
      "\n",
      "Explanation:\n",
      "1. The odd numbers in [4, 8, 9, 15, 12, 2, 1] are [4, 9, 12, 15, 2, 1].\n",
      "2. The sum of these odd numbers is\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = \"\"\"Here are examples of how to compute the sum of odd numbers:\n",
    "Example 1: The odd numbers in [3, 4, 7, 8] are [3, 7]. The sum is 10.\n",
    "Example 2: The odd numbers in [2, 5, 11, 14] are [5, 11]. The sum is 16.\n",
    "Question: What is the sum of the odd numbers in [4, 8, 9, 15, 12, 2, 1]?\"\"\"\n",
    "\n",
    "response_few_shot = falcon_pipeline(\n",
    "    few_shot_prompt,\n",
    "    max_new_tokens=100,  # generated output's length\n",
    "    temperature=0.5,\n",
    "    truncation=True,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_few_shot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff3873-8d1d-4fe8-867a-9e30de3096b8",
   "metadata": {},
   "source": [
    "# Chain-of-thought (CoT) Example\n",
    "* Model's step-by-step reasoning capabilites are evaluated.\n",
    "* Better debugging of logic failure for incorrect answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd64db9a-58d6-4e0a-b887-f86ff6244b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow these steps to compute the sum of odd numbers:\n",
      "Step 1: Identify and list the odd numbers in the list.\n",
      "Step 2: Add the identified odd numbers.\n",
      "Step 3: Repeat steps 1 and 2 until all the odd numbers have been added.\n",
      "Step 4: The sum of odd numbers is the sum of the last two odd numbers in the list.\n"
     ]
    }
   ],
   "source": [
    "cot_prompt = \"\"\"Follow these steps to compute the sum of odd numbers:\n",
    "Step 1: Identify and list the odd numbers in the list.\n",
    "Step 2: Add the identified odd numbers.\"\"\"\n",
    "\n",
    "response_cot = falcon_pipeline(\n",
    "    cot_prompt,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.5,\n",
    "    truncation=True,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_cot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47817aa2-a415-47d0-9519-7c4746a9eff5",
   "metadata": {},
   "source": [
    "# Few-shot CoT Example\n",
    "* The model combines few-shot examples advantages and step-by-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de095798-3999-4e62-a235-4635b037d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are examples of how to compute the sum of odd numbers step-by-step:\n",
      "Example 1:\n",
      "List: [3, 4, 7, 8]\n",
      "Step 1: Identify the odd numbers: [3, 7].\n",
      "Step 2: Compute the sum: 10.\n",
      "\n",
      "Example 2:\n",
      "List: [2, 5, 11, 14]\n",
      "Step 1: Identify the odd numbers: [5, 11].\n",
      "Step 2: Compute the sum: 16.\n",
      "\n",
      "Question:\n",
      "List: [4, 8, 9, 15, 12, 2, 1]\n",
      "Step 1:\n",
      "List: [4, 8, 9, 15, 12, 2, 1]\n",
      "Step 2:\n",
      "Step 3:\n",
      "\n",
      "The sum of odd numbers is 15.\n"
     ]
    }
   ],
   "source": [
    "few_shot_cot_prompt = \"\"\"Here are examples of how to compute the sum of odd numbers step-by-step:\n",
    "Example 1:\n",
    "List: [3, 4, 7, 8]\n",
    "Step 1: Identify the odd numbers: [3, 7].\n",
    "Step 2: Compute the sum: 10.\n",
    "\n",
    "Example 2:\n",
    "List: [2, 5, 11, 14]\n",
    "Step 1: Identify the odd numbers: [5, 11].\n",
    "Step 2: Compute the sum: 16.\n",
    "\n",
    "Question:\n",
    "List: [4, 8, 9, 15, 12, 2, 1]\n",
    "Step 1:\n",
    "\"\"\"\n",
    "response_few_shot_cot = falcon_pipeline(\n",
    "    few_shot_cot_prompt,\n",
    "    max_new_tokens=100,  # Reduce token limit\n",
    "    temperature=0.5,\n",
    "    truncation=True,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_few_shot_cot[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4cd81-557a-4c18-ac73-ab18d9016fb5",
   "metadata": {},
   "source": [
    "# Low Temperature Example\n",
    "* Produces safer outputs that are useful for structured tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8c8333-7f05-4daf-98d0-eaaf3d7bb0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem about a land of candy.\n",
      "A land of sweet delights,\n",
      "Where every taste is found.\n",
      "Sugar-coated confections,\n",
      "In every shape and form.\n",
      "\n",
      "Lollipops of every hue,\n",
      "Dipped in chocolate, pure and true.\n",
      "Gummy bears that tingle,\n",
      "With every bite, they tingle too.\n",
      "\n",
      "Mouth-watering hard candies,\n",
      "In every flavor, from sour to candy.\n",
      "Fruity chews that make you smile,\n",
      "With every chew, your smile will multiply.\n",
      "\n",
      "A land of candy, so delightful,\n",
      "Where every sweet tooth can find its delight.\n"
     ]
    }
   ],
   "source": [
    "low_temp_prompt = \"Write a poem about a land of candy.\"\n",
    "response_low_temp = falcon_pipeline(\n",
    "    low_temp_prompt,\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.2,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_low_temp[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29a918-5e5a-4828-9444-d39bf10aedcc",
   "metadata": {},
   "source": [
    "# High Temperature Example\n",
    "* Produces more creative ouputs that are useful for open-ended tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f17528c-1253-4116-a12d-9a7b479d99e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem about a land of candy.\n",
      "Once upon a sweet kingdom did reside,\n",
      "Where every day was filled with sugary glee.\n",
      "Candy trees grew tall and candy-coated hills,\n",
      "Dusting each sweet surface with a magical thrill.\n",
      "\n",
      "In this confectionery wonderland,\n",
      "One could find a treat to make them feel grand.\n",
      "Gummy bears, sour patches, and lollipops galore,\n",
      "Mouth-watering delicacies, a sugary shore.\n",
      "\n",
      "Candy castles, spun sugar, and rainbow-filled skies,\n",
      "The land of sweet is where each fantasy thrives.\n"
     ]
    }
   ],
   "source": [
    "high_temp_prompt = \"Write a poem about a land of candy.\"\n",
    "response_high_temp = falcon_pipeline(\n",
    "    high_temp_prompt,\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.8,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "print(response_high_temp[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pytorch)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
